"use strict";(self.webpackChunk_mlflow_mlflow=self.webpackChunk_mlflow_mlflow||[]).push([[5167],{14429:function(e,t,n){n.d(t,{UY:function(){return m},VA:function(){return c},oy:function(){return d},vF:function(){return s}});var o=n(46709),a=n(91105),i=n(79444);const s="startTimeLabel",l="startTime",r="endTime",d="LAST_7_DAYS",c=()=>{var e;const t=(0,i.U)(),[n,c]=(0,a.ok)(),u=n.get(s)||d;let g=n.get(l)||void 0,p=null!==(e=n.get(r))&&void 0!==e?e:void 0;if("CUSTOM"!==u){const e=m(t.dateNow,{startTimeLabel:u});g=e.startTime,p=e.endTime}else{var h;g=n.get(l)||void 0,p=null!==(h=n.get(r))&&void 0!==h?h:void 0}const f=(0,o.useMemo)((()=>({startTimeLabel:u,startTime:g,endTime:p})),[u,g,p]),T=(0,o.useCallback)(((e,t=!1)=>{c((t=>(void 0===(null===e||void 0===e?void 0:e.startTime)?t.delete(l):"CUSTOM"===e.startTimeLabel&&t.set(l,e.startTime),void 0===(null===e||void 0===e?void 0:e.endTime)?t.delete(r):"CUSTOM"===e.startTimeLabel&&t.set(r,e.endTime),void 0===(null===e||void 0===e?void 0:e.startTimeLabel)?t.delete(s):t.set(s,e.startTimeLabel),t)),{replace:t})}),[c]);return[f,T]};function m(e,t){return t.startTimeLabel&&"CUSTOM"!==t.startTimeLabel?function(e,t){switch(t){case"LAST_HOUR":return{startTime:new Date(new Date(e).setUTCHours((new Date).getUTCHours()-1)).toISOString(),endTime:e.toISOString()};case"LAST_24_HOURS":return{startTime:new Date(new Date(e).setUTCDate((new Date).getUTCDate()-1)).toISOString(),endTime:e.toISOString()};case"LAST_7_DAYS":return{startTime:new Date(new Date(e).setUTCDate((new Date).getUTCDate()-7)).toISOString(),endTime:e.toISOString()};case"LAST_30_DAYS":return{startTime:new Date(new Date(e).setUTCDate((new Date).getUTCDate()-30)).toISOString(),endTime:e.toISOString()};case"LAST_YEAR":return{startTime:new Date(new Date(e).setUTCFullYear((new Date).getUTCFullYear()-1)).toISOString(),endTime:e.toISOString()};case"ALL":return{startTime:void 0,endTime:e.toISOString()};default:throw new Error(`Unexpected start time label: ${t}`)}}(e,t.startTimeLabel):{startTime:t.startTime,endTime:t.endTime}}},23984:function(e,t,n){n.d(t,{I:function(){return h}});var o=n(68248),a=n(27757),i=n(74060),s=n(30676),l=n(91701),r=(n(46709),n(40724)),d=n(73408);var c={name:"ddxhyk",styles:"max-width:800px"},m={name:"ddxhyk",styles:"max-width:800px"};const u={openai:{minVersion:"2.15.1",getContent:()=>(0,d.Y)(r.A,{id:"smtq2M",defaultMessage:"Automatically log traces for OpenAI API calls by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.openai.autolog()"})}}),getCodeSource:()=>'from openai import OpenAI\n\nmlflow.openai.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nclient = OpenAI()\n\nmessages = [\n  {"role": "system", "content": "You are a helpful assistant."},\n  {"role": "user", "content": "Hello!"}\n]\n\n# Inputs and outputs of the API request will be logged in a trace\nclient.chat.completions.create(model="gpt-4o-mini", messages=messages)'},langchain:{minVersion:"2.17.2",getContent:()=>(0,d.Y)(r.A,{id:"7/urtn",defaultMessage:"Automatically log traces for LangChain or LangGraph invocations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.langchain.autolog()"})}}),getCodeSource:()=>'from langchain_openai import OpenAI\nfrom langchain_core.prompts import PromptTemplate\n\nmlflow.langchain.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nllm = OpenAI()\nprompt = PromptTemplate.from_template("Answer the following question: {question}")\nchain = prompt | llm\n\n# Invoking the chain will cause a trace to be logged\nchain.invoke("What is MLflow?")'},langgraph:{minVersion:"2.19.0",getContent:()=>(0,d.Y)(r.A,{id:"dvL+4V",defaultMessage:"Automatically log traces for LangGraph workflows by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.langgraph.autolog()"})}}),getCodeSource:()=>'from langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph\nfrom typing import Annotated\n\nmlflow.langgraph.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nmodel = ChatOpenAI(model="gpt-4o-mini")\n\n# Define a minimal LangGraph workflow\nclass GraphState(dict):\n    input: Annotated[str, "input"]\n\ndef call_model(state: GraphState) -> GraphState:\n    response = model.invoke(state["input"])\n    return {"input": state["input"], "response": response.content}\n\ngraph = StateGraph(GraphState)\ngraph.add_node("model", call_model)\ngraph.set_entry_point("model")\napp = graph.compile()\n\n# Executing the graph will log the steps as a trace\napp.invoke({"input": "Say hello to MLflow."})'},llama_index:{minVersion:"2.15.1",getContent:()=>(0,d.Y)(r.A,{id:"/v6KuF",defaultMessage:"Automatically log traces for LlamaIndex queries by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.llama_index.autolog()"})}}),getCodeSource:()=>'from llama_index.core import Document, VectorStoreIndex\n\nmlflow.llama_index.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nindex = VectorStoreIndex.from_documents([Document.example()])\nquery_engine = index.as_query_engine()\n\n# Querying the engine will cause a trace to be logged\nquery_engine.query("What is LlamaIndex?")'},dspy:{minVersion:"2.18.0",getContent:()=>(0,d.Y)(r.A,{id:"h1HQ14",defaultMessage:"Automatically log traces for DSPy executions by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.dspy.autolog()"})}}),getCodeSource:()=>'import dspy\n\nmlflow.dspy.autolog()\n\n# Configure the LLM to use. Please ensure that\n# the OPENAI_API_KEY environment variable is set\nlm = dspy.LM("openai/gpt-4o-mini")\ndspy.configure(lm=lm)\n\n# Define a simple chain-of-thought model and run it\nmath = dspy.ChainOfThought("question -> answer: float")\nquestion = "Two dice are tossed. What is the probability that the sum equals two?"\n\n# All intermediate outputs from the execution will be logged\nmath(question=question)'},crewai:{minVersion:"2.19.0",getContent:()=>(0,d.Y)(r.A,{id:"K8LdMX",defaultMessage:"Automatically log traces for CrewAI executions by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.crewai.autolog()"})}}),getCodeSource:()=>'from crewai import Agent, Crew, Process, Task\n\nmlflow.crewai.autolog()\n\ncity_selection_agent = Agent(\n    role="City selection expert",\n    goal="Select the best city based on weather, season, and prices",\n    backstory="An expert in analyzing travel data to pick ideal destinations",\n    allow_delegation=True,\n    verbose=True,\n)\n\nlocal_expert = Agent(\n    role="Local expert",\n    goal="Provide the best insights about the selected city",\n    backstory="A local guide with extensive information about the city",\n    verbose=True,\n)\n  \nplan_trip = Task(\n    name="Plan a trip",\n    description="""Plan a trip to a city based on weather, prices, and best local attractions. \n    Please consult with a local expert when researching things to do.""",\n    expected_output="A short summary of the trip destination and key things to do",\n    agent=city_selection_agent,\n)\n\ncrew = Crew(\n  agents=[\n    city_selection_agent,\n    local_expert,\n  ],\n  tasks=[plan_trip],\n  process=Process.sequential\n)\n\n# Ensure the "OPENAI_API_KEY" environment variable is set\n# before kicking off the crew. All intermediate agent outputs\n# will be logged in the resulting trace.\ncrew.kickoff()'},autogen:{minVersion:"2.16.2",getContent:()=>(0,d.Y)(r.A,{id:"i/pJvo",defaultMessage:"Automatically log traces for AutoGen conversations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.autogen.autolog()"})}}),getCodeSource:()=>'import os\nfrom autogen import AssistantAgent, UserProxyAgent\n\nmlflow.autogen.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nllm_config = { "model": "gpt-4o-mini", "api_key": os.environ["OPENAI_API_KEY"] }\nassistant = AssistantAgent("assistant", llm_config = llm_config)\nuser_proxy = UserProxyAgent("user_proxy", code_execution_config = False)\n\n# All intermediate executions within the chat session will be logged\nuser_proxy.initiate_chat(assistant, message = "What is MLflow?", max_turns = 1)'},anthropic:{minVersion:"2.19.0",getContent:()=>(0,d.Y)(r.A,{id:"AzOnmT",defaultMessage:"Automatically log traces for Anthropic API calls by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.anthropic.autolog()"})}}),getCodeSource:()=>'import os\nimport anthropic\n\n# Enable auto-tracing for Anthropic\nmlflow.anthropic.autolog()\n\n# Configure your API key (please ensure that the "ANTHROPIC_API_KEY" environment variable is set)\nclient = anthropic.Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])\n\n# Inputs and outputs of API calls will be logged as a trace\nmessage = client.messages.create(\n    model="claude-3-5-sonnet-20241022",\n    max_tokens=1024,\n    messages=[\n        {"role": "user", "content": "Hello, Claude"},\n    ],\n)'},bedrock:{minVersion:"2.20.0",getContent:()=>(0,d.Y)(r.A,{id:"6tKW1I",defaultMessage:"Automatically log traces for Bedrock conversations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.bedrock.autolog()"})}}),getCodeSource:()=>'import boto3\n\nmlflow.bedrock.autolog()\n\n# Ensure that your boto3 client has the necessary auth information\nbedrock = boto3.client(\n    service_name="bedrock-runtime",\n    region_name="<REPLACE_WITH_YOUR_AWS_REGION>",\n)\n\nmodel = "anthropic.claude-3-5-sonnet-20241022-v2:0"\nmessages = [{ "role": "user", "content": [{"text": "Hello!"}]}]\n\n# All intermediate executions within the chat session will be logged\nbedrock.converse(modelId=model, messages=messages)'},litellm:{minVersion:"2.18.0",getContent:()=>(0,d.Y)(r.A,{id:"D7SSDK",defaultMessage:"Automatically log traces for LiteLLM API calls by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.litellm.autolog()"})}}),getCodeSource:()=>'import litellm\n\nmlflow.litellm.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nmessages = [{"role": "user", "content": "Hello!"}]\n\n# Inputs and outputs of the API request will be logged in a trace\nlitellm.completion(model="gpt-4o-mini", messages=messages)'},gemini:{minVersion:"2.18.0",getContent:()=>(0,d.Y)(r.A,{id:"IsIgE2",defaultMessage:"Automatically log traces for Gemini conversations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.gemini.autolog()"})}}),getCodeSource:()=>'import google.genai as genai\n\nmlflow.gemini.autolog()\n\n# Replace "GEMINI_API_KEY" with your API key\nclient = genai.Client(api_key="GEMINI_API_KEY")\n\n# Inputs and outputs of the API request will be logged in a trace\nclient.models.generate_content(model="gemini-1.5-flash", contents="Hello!")'},custom:{minVersion:"2.14.3",getContent:e=>(0,d.FD)(d.FK,{children:[(0,d.Y)(a.T.Paragraph,{css:c,children:(0,d.Y)(r.A,{id:"3Z6K+n",defaultMessage:"To manually instrument your own traces, the most convenient method is to use the {code} function decorator. This will cause the inputs and outputs of the function to be captured in the trace.",values:{code:(0,d.Y)("code",{children:"@mlflow.trace"})}})}),(0,d.Y)(a.T.Paragraph,{css:m,children:(0,d.Y)(r.A,{id:"WNz02j",defaultMessage:"For more complex use cases, MLflow also provides granular APIs that can be used to control tracing behavior. For more information, please visit the <a>official documentation</a> on fluent and client APIs for MLflow Tracing.",values:{a:t=>(0,d.Y)(a.T.Link,{title:"official documentation",componentId:`${e}.traces_table.custom_tracing_docs_link`,href:"https://mlflow.org/docs/latest/llms/tracing/index.html#tracing-fluent-apis",openInNewTab:!0,children:t})}})})]}),getCodeSource:()=>'@mlflow.trace\ndef foo(a):\nreturn a + bar(a)\n\n# Various attributes can be passed to the decorator\n# to modify the information contained in the span\n@mlflow.trace(name = "custom_name", attributes = { "key": "value" })\ndef bar(b):\nreturn b + 1\n\n# Invoking the traced function will cause a trace to be logged\nfoo(1)'}};var g={name:"ddxhyk",styles:"max-width:800px"},p={name:"1hyob9y",styles:"position:relative;width:min-content"};const h=({flavorName:e,baseComponentId:t})=>{const{theme:n}=(0,a.u)(),{getContent:r,getCodeSource:c,minVersion:m}=u[e],h=r(t),f=c();return(0,d.FD)("div",{children:[(0,d.Y)(a.T.Text,{css:g,color:"secondary",children:h}),(0,d.FD)("div",{css:p,children:[(0,d.Y)(l.i,{componentId:`${t}.traces_table.${e}_quickstart_snippet_copy`,css:(0,o.AH)({zIndex:1,position:"absolute",top:n.spacing.xs,right:n.spacing.xs},""),showLabel:!1,copyText:f,icon:(0,d.Y)(i.CopyIcon,{})}),(0,d.Y)(s.z7,{showLineNumbers:!0,theme:n.isDarkMode?"duotoneDark":"light",style:{padding:`${n.spacing.sm}px ${n.spacing.md}px`,marginTop:n.spacing.md},language:"python",children:f})]})]})}},39767:function(e,t,n){n.d(t,{i:function(){return m}});var o=n(68248),a=n(27757),i=n(74060),s=n(40724),l=n(76118),r=n(23984),d=n(63394),c=n(73408);const m=({baseComponentId:e,runUuid:t})=>{const{theme:n}=(0,a.u)(),{introductionText:m}=(0,d.S)();return(0,c.FD)("div",{css:(0,o.AH)({overflow:"auto",paddingBottom:n.spacing.lg},""),children:[(0,c.Y)(i.Header,{title:(0,c.Y)(s.A,{id:"6d5JTO",defaultMessage:"No traces recorded"}),titleElementLevel:3}),(0,c.Y)(a.T.Text,{css:(0,o.AH)({display:"block",marginTop:n.spacing.md,marginBottom:n.spacing.md,maxWidth:800},""),children:m||(0,c.Y)(s.A,{id:"msYDmK",defaultMessage:"This tab displays all the traces logged to this {isRun, select, true {run} other {experiment}}. Follow the steps below to log your first trace. For more information about MLflow Tracing, visit the <a>MLflow documentation</a>.",values:{isRun:!(0,l.isNil)(t),a:t=>(0,c.Y)(a.T.Link,{componentId:`${e}.traces_table.quickstart_docs_link`,href:"https://mlflow.org/docs/latest/llms/tracing/index.html",openInNewTab:!0,children:t})}})}),(0,c.Y)(r.I,{flavorName:"custom",baseComponentId:e})]})}},63394:function(e,t,n){n.d(t,{A:function(){return s},S:function(){return l}});var o=n(46709),a=n(73408);const i=(0,o.createContext)({}),s=({children:e,introductionText:t,displayVersionWarnings:n})=>(0,a.Y)(i.Provider,{value:{introductionText:t,displayVersionWarnings:n},children:e}),l=()=>(0,o.useContext)(i)},79444:function(e,t,n){n.d(t,{U:function(){return d},k:function(){return r}});var o=n(76118),a=n(46709),i=n(73408);const s=()=>({dateNow:new Date,lastRefreshTime:Date.now(),refresh:()=>{}}),l=(0,a.createContext)(s()),r=({config:e,children:t})=>{const n=s(),r=(0,o.merge)({},n,e),[d,c]=a.useState(r.lastRefreshTime),m=(0,a.useMemo)((()=>new Date(d)),[d]),u=(0,a.useCallback)((()=>{c(Date.now())}),[]);return(0,i.Y)(l.Provider,{value:{...r,dateNow:m,lastRefreshTime:d,refresh:u},children:t})},d=()=>{const e=(0,a.useContext)(l);return e||s()}},85167:function(e,t,n){n.d(t,{v:function(){return L}});var o=n(46709),a=n(74060),i=n(27757),s=n(92831),l=n(33656),r=n(31655),d=n(40720),c=n(88525),m=n(42747),u=n(69986),g=n(14429),p=n(66916),h=n(92338),f=n(54741),T=n(91944),y=n(44105),A=n(39767),I=n(73408);const w=e=>{const{experimentIds:t,loggedModelId:n}=e,l=(0,m.tz)(),{data:r,isLoading:d,error:c}=(0,s.Zn)({experimentId:t[0],pageSize:1,limit:1,...n?{filterByLoggedModelId:n}:{}}),{data:u,loading:w}=(0,f.L)({experimentId:t[0]}),b=u,_=(0,T.BH)(null===b||void 0===b?void 0:b.tags),v=(_===y.Gk.GENAI_DEVELOPMENT||y.Gk.GENAI_DEVELOPMENT_INFERRED,r&&r.length>0),[x,S]=(0,g.VA)(),C=(0,o.useMemo)((()=>(0,h.p)(l)),[l]),Y=(0,I.Y)(i.B,{componentId:"traces-v3-empty-state-button",onClick:()=>S({startTimeLabel:"ALL"}),children:(0,I.Y)(m.sA,{id:"WpD2MA",defaultMessage:"View All"})});if(d||w)return(0,I.Y)(I.FK,{children:[...Array(10).keys()].map((e=>(0,I.Y)(a.ParagraphSkeleton,{label:"Loading...",seed:`s-${e}`},e)))});if(c)return(0,I.Y)(a.Empty,{image:(0,I.Y)(i.k,{}),title:(0,I.Y)(m.sA,{id:"ZotI2j",defaultMessage:"Fetching traces failed"}),description:String(c)});if(v){var M;const e=(0,I.Y)(p.S,{}),t=(0,I.Y)(m.sA,{id:"XuzIWs",defaultMessage:'Some traces are hidden by your time range filter: "{filterLabel}"',values:{filterLabel:(0,I.Y)("strong",{children:(null===(M=C.find((e=>e.key===x.startTimeLabel)))||void 0===M?void 0:M.label)||""})}});return(0,I.Y)(a.Empty,{title:(0,I.Y)(m.sA,{id:"Dhr3pC",defaultMessage:"No traces found"}),description:t,button:Y,image:e})}return(0,I.Y)(A.i,{baseComponentId:"mlflow.traces"})};var b=n(39595),_=n(91105);var v=n(82636),x=n(19114);var S={name:"1dd35ky",styles:"display:flex;flex:1;overflow:hidden"},C={name:"1dd35ky",styles:"display:flex;flex:1;overflow:hidden"},Y={name:"db3fum",styles:"display:flex;flex-direction:column;width:100%;gap:8px;padding:16px"},M={name:"1w1qal4",styles:"display:flex;align-items:center;justify-content:center;width:100%;height:100%"},E={name:"1nxh63r",styles:"overflow-y:hidden;height:100%;display:flex;flex-direction:column"};const L=o.memo((({experimentId:e,endpointName:t,timeRange:n,loggedModelId:p})=>{const h=(0,l.N9)(),f=(0,m.tz)(),T=(0,r.rE)(),{assessmentInfos:y,allColumns:A,totalCount:L,isLoading:k,evaluatedTraces:D,error:O,isEmpty:P,tableFilterOptions:N}=(0,s.KW)({experimentId:e,timeRange:n,filterByLoggedModelId:p}),[F,R]=(0,o.useState)(""),[U,H]=(0,s.R7)(),V=(0,b.jE)(),K=(0,o.useCallback)((e=>{const{responseHasContent:t,inputHasContent:n,tokensHasContent:o}=(0,v.l)(D);return e.filter((e=>e.type===s.$6.ASSESSMENT||e.type===s.$6.EXPECTATION||n&&e.type===s.$6.INPUT||t&&e.type===s.$6.TRACE_INFO&&e.id===s.Rl||o&&e.type===s.$6.TRACE_INFO&&e.id===s.YO||e.type===s.$6.TRACE_INFO&&[s.XQ,s.tj,s.Te,s.$W].includes(e.id)||e.type===s.$6.INTERNAL_MONITOR_REQUEST_TIME))}),[D]),{selectedColumns:q,toggleColumns:G,setSelectedColumns:$}=(0,s.K0)(e,A,K),[W,z]=(0,s.GY)(q,{key:s.Te,type:s.$6.TRACE_INFO,asc:!1}),{isInitialTimeFilterLoading:B}=(({experimentId:e,isTracesEmpty:t,isTraceMetadataLoading:n})=>{const[o]=(0,_.ok)(),[a,i]=(0,g.VA)(),l=t&&!n&&!o.has(g.vF),{data:r,isLoading:d}=(0,s.Zn)({experimentId:e,tableSort:{key:s.Te,type:s.$6.TRACE_INFO,asc:!1},disabled:!l,limit:500,pageSize:500});l&&r&&r.length>0&&!d&&i({startTimeLabel:"CUSTOM",startTime:r[r.length-1].request_time,endTime:(new Date).toISOString()});return{isInitialTimeFilterLoading:l&&d}})({experimentId:e,isTracesEmpty:P,isTraceMetadataLoading:k}),{data:Q,isLoading:j,error:X}=(0,s.Zn)({experimentId:e,currentRunDisplayName:t,searchQuery:F,filters:U,timeRange:n,filterByLoggedModelId:p,tableSort:W}),Z=(0,d.C)(),{showEditTagsModalForTrace:J,EditTagsModal:ee}=(0,c.$)({onSuccess:()=>(0,s.BL)({queryClient:V}),existingTagKeys:(0,s.d9)(Q||[]),useV3Apis:!0}),{showExportTracesToDatasetsModal:te,setShowExportTracesToDatasetsModal:ne,renderExportTracesToDatasetsModal:oe}=(0,x.c)({experimentId:e}),ae=(0,o.useMemo)((()=>({deleteTracesAction:{deleteTraces:(e,t)=>Z.mutateAsync({experimentId:e,traceRequestIds:t})},exportToEvals:{showExportTracesToDatasetsModal:te,setShowExportTracesToDatasetsModal:ne,renderExportTracesToDatasetsModal:oe},editTags:{showEditTagsModalForTrace:J,EditTagsModal:ee}})),[te,ne,oe,J,ee,Z]),ie=(0,o.useMemo)((()=>({currentCount:null===Q||void 0===Q?void 0:Q.length,logCountLoading:j,totalCount:L,maxAllowedCount:(0,s.pR)()})),[Q,L,j]),se=j||B||k,le=X||O,re=P&&!se&&!le;return!T&&re?(0,I.Y)(w,{experimentIds:[e],loggedModelId:p}):(0,I.Y)(s.sG,{children:(0,I.FD)("div",{css:E,children:[(0,I.Y)(s.w_,{experimentId:e,searchQuery:F,setSearchQuery:R,filters:U,setFilters:H,assessmentInfos:y,traceInfos:Q,tableFilterOptions:N,countInfo:ie,traceActions:ae,tableSort:W,setTableSort:z,allColumns:A,selectedColumns:q,toggleColumns:G,setSelectedColumns:$,isMetadataLoading:k,metadataError:O}),!T&&re?(0,I.Y)(w,{experimentIds:[e],loggedModelId:p}):(0,I.Y)("div",{css:S,children:(0,I.Y)("div",{css:C,children:se?(0,I.Y)("div",{css:Y,children:[...Array(10).keys()].map((e=>(0,I.Y)(a.ParagraphSkeleton,{label:"Loading...",seed:`s-${e}`},e)))}):le?(0,I.Y)("div",{css:M,children:(0,I.Y)(a.Empty,{image:(0,I.Y)(i.k,{}),title:f.formatMessage({id:"Bcr4hl",defaultMessage:"Fetching traces failed"}),description:le.message})}):(0,I.Y)(s.tU,{makeHtml:h,children:(0,I.Y)(s._p,{experimentId:e,allColumns:A,currentTraceInfoV3:Q||[],currentRunDisplayName:t,getTrace:u.U,assessmentInfos:y,setFilters:H,filters:U,selectedColumns:q,tableSort:W})})})})]})})}))},92338:function(e,t,n){function o(e){return[{key:"LAST_HOUR",label:e.formatMessage({id:"bjoGjg",defaultMessage:"Last hour"})},{key:"LAST_24_HOURS",label:e.formatMessage({id:"JChRnq",defaultMessage:"Last 24 hours"})},{key:"LAST_7_DAYS",label:e.formatMessage({id:"eQsXm7",defaultMessage:"Last 7 days"})},{key:"LAST_30_DAYS",label:e.formatMessage({id:"p1H1KR",defaultMessage:"Last 30 days"})},{key:"LAST_YEAR",label:e.formatMessage({id:"EI7moF",defaultMessage:"Last year"})},{key:"ALL",label:e.formatMessage({id:"HeNa8H",defaultMessage:"All"})},{key:"CUSTOM",label:e.formatMessage({id:"TpmJlu",defaultMessage:"Custom"})}]}n.d(t,{p:function(){return o}})}}]);